{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "452ca30a3ce0a2dc1b59b3f84f0c7f02ccbd7319"
   },
   "source": [
    "**This is an example from Deep Learning With Python book.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:26:31.569986Z",
     "iopub.status.busy": "2021-11-19T13:26:31.569519Z",
     "iopub.status.idle": "2021-11-19T13:26:31.575553Z",
     "shell.execute_reply": "2021-11-19T13:26:31.574504Z",
     "shell.execute_reply.started": "2021-11-19T13:26:31.569942Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "76c00e3b6e596e30ba6728c95ef323389dca5537"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:19:04.846554Z",
     "iopub.status.busy": "2021-11-19T13:19:04.846008Z",
     "iopub.status.idle": "2021-11-19T13:19:05.649446Z",
     "shell.execute_reply": "2021-11-19T13:19:05.648435Z",
     "shell.execute_reply.started": "2021-11-19T13:19:04.846507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:21:19.382819Z",
     "iopub.status.busy": "2021-11-19T13:21:19.382190Z",
     "iopub.status.idle": "2021-11-19T13:21:19.392749Z",
     "shell.execute_reply": "2021-11-19T13:21:19.392040Z",
     "shell.execute_reply.started": "2021-11-19T13:21:19.382771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:21:00.930131Z",
     "iopub.status.busy": "2021-11-19T13:21:00.929821Z",
     "iopub.status.idle": "2021-11-19T13:21:00.938142Z",
     "shell.execute_reply": "2021-11-19T13:21:00.937157Z",
     "shell.execute_reply.started": "2021-11-19T13:21:00.930083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80846e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        2.72500e+01, 2.90500e+01],\n",
       "       [1.23290e-01, 0.00000e+00, 1.00100e+01, ..., 1.78000e+01,\n",
       "        3.94950e+02, 1.62100e+01],\n",
       "       [5.49700e-02, 0.00000e+00, 5.19000e+00, ..., 2.02000e+01,\n",
       "        3.96900e+02, 9.74000e+00],\n",
       "       ...,\n",
       "       [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        3.89610e+02, 1.92000e+00],\n",
       "       [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
       "        3.91700e+02, 9.71000e+00],\n",
       "       [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.40160e+02, 9.81000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "46abef54b50bee09d016f30786d79dda2171ad3c",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:21:39.812225Z",
     "iopub.status.busy": "2021-11-19T13:21:39.811687Z",
     "iopub.status.idle": "2021-11-19T13:21:39.818867Z",
     "shell.execute_reply": "2021-11-19T13:21:39.818165Z",
     "shell.execute_reply.started": "2021-11-19T13:21:39.812161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data : (404, 13)\n",
      "Test data : (102, 13)\n",
      "Training sample : [  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
      "Training target sample : 15.2\n"
     ]
    }
   ],
   "source": [
    "# take a look at the data\n",
    "\n",
    "print(f'Training data : {train_data.shape}')\n",
    "print(f'Test data : {test_data.shape}')\n",
    "print(f'Training sample : {train_data[0]}')\n",
    "print(f'Training target sample : {train_targets[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06d8318b1e09e6dffb161fab36b324a309b25b6a"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "We are going to do a feature normalization . Feature normalizaion is when you subtract the mean of the feature from each feature and divide each result by the standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "fb47c40e26f4a56384584910c748eea00cfd7159",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:27:37.882555Z",
     "iopub.status.busy": "2021-11-19T13:27:37.882210Z",
     "iopub.status.idle": "2021-11-19T13:27:37.887511Z",
     "shell.execute_reply": "2021-11-19T13:27:37.886829Z",
     "shell.execute_reply.started": "2021-11-19T13:27:37.882469Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "# Note that the quantities used for normalizing the test data are computed using the\n",
    "# training data. You should never use in your workflow any quantity computed on the\n",
    "# test data, even for something as simple as data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26834f67baa2de9d4b516b1f8eaafc5737276fce"
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4cbaa8646f81bab4261e9c25474cef65b2fc8474",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:33:21.427253Z",
     "iopub.status.busy": "2021-11-19T13:33:21.426630Z",
     "iopub.status.idle": "2021-11-19T13:33:21.435258Z",
     "shell.execute_reply": "2021-11-19T13:33:21.434610Z",
     "shell.execute_reply.started": "2021-11-19T13:33:21.427183Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bddd23bd4517bcbedb3e264249a39cf851a9acfd"
   },
   "source": [
    "## K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e9ccbfd3c006f5a51da9e83809f601cf651c02dc",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:46:19.400719Z",
     "iopub.status.busy": "2021-11-19T13:46:19.400353Z",
     "iopub.status.idle": "2021-11-19T13:48:08.984682Z",
     "shell.execute_reply": "2021-11-19T13:48:08.983780Z",
     "shell.execute_reply.started": "2021-11-19T13:46:19.400660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold # 0\n",
      "Processing fold # 1\n",
      "Processing fold # 2\n",
      "Processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(f'Processing fold # {i}')\n",
    "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "                            [train_data[:i * num_val_samples],\n",
    "                            train_data[(i+1) * num_val_samples:]],\n",
    "                            axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "                            [train_targets[:i * num_val_samples],\n",
    "                            train_targets[(i+1)*num_val_samples:]],\n",
    "                            axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data,\n",
    "              partial_train_targets,\n",
    "              epochs=num_epochs,\n",
    "              batch_size=1,\n",
    "              verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5a9f7c987f6f29ea22a03c3df0688d9e38ea8f05",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:49:25.239503Z",
     "iopub.status.busy": "2021-11-19T13:49:25.239022Z",
     "iopub.status.idle": "2021-11-19T13:49:25.244587Z",
     "shell.execute_reply": "2021-11-19T13:49:25.243421Z",
     "shell.execute_reply.started": "2021-11-19T13:49:25.239438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_scores : [2.1528491973876953, 2.421501874923706, 2.7859079837799072, 2.4004688262939453]\n",
      "mean all scores : 2.4401819705963135\n"
     ]
    }
   ],
   "source": [
    "print(f'all_scores : {all_scores}')\n",
    "print(f'mean all scores : {np.mean(all_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "328b6245ae5d964df08f14de6236bc68147c5611",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:52:22.112462Z",
     "iopub.status.busy": "2021-11-19T13:52:22.111841Z",
     "iopub.status.idle": "2021-11-19T13:52:24.844362Z",
     "shell.execute_reply": "2021-11-19T13:52:24.843480Z",
     "shell.execute_reply.started": "2021-11-19T13:52:22.112214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 15.3338 - mae: 2.4827\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "174d90326f6ed72d9127f6cf8d0619a4820d56e5",
    "execution": {
     "iopub.execute_input": "2021-11-19T13:59:10.045798Z",
     "iopub.status.busy": "2021-11-19T13:59:10.045069Z",
     "iopub.status.idle": "2021-11-19T13:59:10.052261Z",
     "shell.execute_reply": "2021-11-19T13:59:10.051559Z",
     "shell.execute_reply.started": "2021-11-19T13:59:10.045379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4827449321746826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
